{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Nueral Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Importing dataset\n",
    "dataset = pd.read_csv('datasets/Churn_Modelling.csv')\n",
    "\n",
    "# Separate dataset (X) and dependent vector (y)\n",
    "X = dataset.drop(['Exited', 'RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "y = dataset.filter(items=['Exited'])\n",
    "\n",
    "# Encode Categorical Data\n",
    "dummy_vars = ['Geography', 'Gender']\n",
    "X_categorical = pd.get_dummies(X[dummy_vars])\n",
    "X = pd.concat([X_categorical, X.drop(columns=dummy_vars)], axis = 1, sort=False)\n",
    "\n",
    "# Avoid the dummy variable trap!(Unless the library handles it for you ...)\n",
    "X.drop(['Geography_Germany', 'Gender_Male'], axis=1, inplace=True)\n",
    "\n",
    "# Splitting Training and Test Set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Feature Scaling - Nueral Nets ... this set is compulsory!\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = pd.DataFrame(sc_X.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test = pd.DataFrame(sc_X.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "y_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Add the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation='relu', input_dim = 11))\n",
    "\n",
    "# Add the second hidden layer\n",
    "classifier.add(Dense(output_dim = 6, init = 'uniform', activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/40\n8000/8000 [==============================] - 1s 161us/step - loss: 0.5046 - accuracy: 0.7952\nEpoch 2/40\n8000/8000 [==============================] - 1s 134us/step - loss: 0.4133 - accuracy: 0.8074\nEpoch 3/40\n8000/8000 [==============================] - 1s 145us/step - loss: 0.3867 - accuracy: 0.8239\nEpoch 4/40\n8000/8000 [==============================] - 1s 128us/step - loss: 0.3675 - accuracy: 0.8489\nEpoch 5/40\n8000/8000 [==============================] - 1s 124us/step - loss: 0.3567 - accuracy: 0.8553\nEpoch 6/40\n8000/8000 [==============================] - 1s 123us/step - loss: 0.3514 - accuracy: 0.8583\nEpoch 7/40\n8000/8000 [==============================] - 1s 129us/step - loss: 0.3483 - accuracy: 0.8590\nEpoch 8/40\n8000/8000 [==============================] - 1s 138us/step - loss: 0.3466 - accuracy: 0.8587\nEpoch 9/40\n8000/8000 [==============================] - 1s 129us/step - loss: 0.3447 - accuracy: 0.8594\nEpoch 10/40\n8000/8000 [==============================] - 1s 138us/step - loss: 0.3438 - accuracy: 0.8601\nEpoch 11/40\n8000/8000 [==============================] - 1s 130us/step - loss: 0.3425 - accuracy: 0.8601\nEpoch 12/40\n8000/8000 [==============================] - 1s 129us/step - loss: 0.3418 - accuracy: 0.8583\nEpoch 13/40\n8000/8000 [==============================] - 1s 126us/step - loss: 0.3406 - accuracy: 0.8602\nEpoch 14/40\n8000/8000 [==============================] - 1s 127us/step - loss: 0.3405 - accuracy: 0.8608\nEpoch 15/40\n8000/8000 [==============================] - 1s 125us/step - loss: 0.3403 - accuracy: 0.8597\nEpoch 16/40\n8000/8000 [==============================] - 1s 124us/step - loss: 0.3392 - accuracy: 0.8625\nEpoch 17/40\n8000/8000 [==============================] - 1s 123us/step - loss: 0.3393 - accuracy: 0.8600\nEpoch 18/40\n8000/8000 [==============================] - 1s 124us/step - loss: 0.3382 - accuracy: 0.8619\nEpoch 19/40\n8000/8000 [==============================] - 1s 128us/step - loss: 0.3384 - accuracy: 0.8614\nEpoch 20/40\n8000/8000 [==============================] - 1s 124us/step - loss: 0.3380 - accuracy: 0.8610\nEpoch 21/40\n8000/8000 [==============================] - 1s 122us/step - loss: 0.3380 - accuracy: 0.8630\nEpoch 22/40\n8000/8000 [==============================] - 1s 122us/step - loss: 0.3374 - accuracy: 0.8631\nEpoch 23/40\n8000/8000 [==============================] - 1s 127us/step - loss: 0.3378 - accuracy: 0.8600\nEpoch 24/40\n8000/8000 [==============================] - 1s 120us/step - loss: 0.3373 - accuracy: 0.8627\nEpoch 25/40\n8000/8000 [==============================] - 1s 127us/step - loss: 0.3372 - accuracy: 0.8622\nEpoch 26/40\n8000/8000 [==============================] - 1s 131us/step - loss: 0.3369 - accuracy: 0.8615\nEpoch 27/40\n8000/8000 [==============================] - 1s 120us/step - loss: 0.3367 - accuracy: 0.8631\nEpoch 28/40\n8000/8000 [==============================] - 1s 121us/step - loss: 0.3364 - accuracy: 0.8627\nEpoch 29/40\n8000/8000 [==============================] - 1s 124us/step - loss: 0.3362 - accuracy: 0.8633\nEpoch 30/40\n8000/8000 [==============================] - 1s 126us/step - loss: 0.3360 - accuracy: 0.8629\nEpoch 31/40\n8000/8000 [==============================] - 1s 128us/step - loss: 0.3354 - accuracy: 0.8635\nEpoch 32/40\n8000/8000 [==============================] - 1s 123us/step - loss: 0.3356 - accuracy: 0.8635\nEpoch 33/40\n8000/8000 [==============================] - 1s 125us/step - loss: 0.3356 - accuracy: 0.8629\nEpoch 34/40\n8000/8000 [==============================] - 1s 125us/step - loss: 0.3348 - accuracy: 0.8652\nEpoch 35/40\n8000/8000 [==============================] - 1s 122us/step - loss: 0.3351 - accuracy: 0.8641\nEpoch 36/40\n8000/8000 [==============================] - 1s 123us/step - loss: 0.3349 - accuracy: 0.8652\nEpoch 37/40\n8000/8000 [==============================] - 1s 126us/step - loss: 0.3349 - accuracy: 0.8640\nEpoch 38/40\n8000/8000 [==============================] - 1s 125us/step - loss: 0.3350 - accuracy: 0.8643\nEpoch 39/40\n8000/8000 [==============================] - 1s 124us/step - loss: 0.3351 - accuracy: 0.8636\nEpoch 40/40\n8000/8000 [==============================] - 1s 129us/step - loss: 0.3342 - accuracy: 0.8634\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.callbacks.History at 0x7f1b9e1be7f0>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "# Fitting the ANN tot he Training set\n",
    "classifier.fit(X_train, y_train, batch_size=10, nb_epoch=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[1525   70]\n [ 212  193]]\n"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = pd.DataFrame(classifier.predict(X_test), columns=y_test.columns)\n",
    "\n",
    "# Making the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred.round())\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bitenvvenve0b9c18c3ad345b987724f3a9266ddde",
   "display_name": "Python 3.6.9 64-bit ('env': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}